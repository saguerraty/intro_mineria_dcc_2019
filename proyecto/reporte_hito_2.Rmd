---
title: "Informe hito 2"
author: '@saguerraty @Bastyz @HaineAnn'
date: "October 6, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Avance Hito 2

```{r paquetes y setup , message=FALSE, echo=FALSE, message=FALSE}
library(readr)
library(sqldf)
library(rprojroot)
library(ggplot2)
library(nnet)
library(stats)
library(ROCR)
library(rpart)
library(PRROC)
library(corrplot)
library(here)
setwd(here())
# confirma que el WD esté bien configurado
getwd()
```
## Contexto y motivación
El proyecto se propone resolver determinar si con las herramientas del curso "Es posible mejorar el sistema de determinación de alerta ambiental en Santiago", específicamente: 
'Cómo determinan los factores medio ambientales observables el nivel de material particulado en Santiago'"

Lo que se traduce en un problema de clasificación multiclase, dado que existe más de un tipo de condición de alerta ambiental, con el objetivo de determinar la condición de alerta ambiental (nuestra etiqueta) en función de parámetros observables derivados de estaciones de monitoreo ambiental en la ciudad de Santiago, Chile desde 1997 hasta el presente.

El valor que presenta encontrar una mejora en el método utilizado para determinar una categoría de alerta ambiental va en:

1- Cuantificar el efecto de las variables utilizadas en la determinación de una situación de alerta ambientas (considerando algún grado de interpretabilidad en el modelo utilizado, esto no se mantiene para algo como un clasificador con un perceptron multicapa)

2- La disminución de la carga laboral en HH asignada a determinar una situación de alerta o emergencia ambiental, ya que la aplicación del modelo técnicamente se puede automatizar.

3- La mejora en la planificación de la ciudadanía al permitir advertir una situación de emergencia ambiental mediante regresores y luego el clasificador, con más anticipación de lo que se hace actualmente, es decir, se podría advertir con anticipación cuando hay una alta probabilidad de que se decrete una emergencia ambiental.


```{r leer datos y mergear , message=FALSE , echo=FALSE, warning=FALSE}
emergencia=read_csv("./scrapping_emergencia_aire/predLimpias.csv")
atmos=read_csv("./ClimaYEmisionesData/DatosHito1CleanWithDates.csv")

#arreglar error de formato en pre emergencia por variaciones inesperadas en PREEMERGENCIA
emergencia$'ESTADO MP10'[emergencia$`ESTADO MP10`=="PREEMERGENCIA"]<-"PRE EMERGENCIA"

tabla=sqldf("SELECT atmos.*,
            emergencia.'ESTADO MP10' as 'cat_mp10',
            emergencia.'ESTADO MP2,5' as 'cat_mp25' 
            FROM atmos JOIN emergencia ON atmos.Fecha = emergencia.Fecha", drv="SQLite")

tabla$MP10<-as.numeric(tabla$MP10)
tabla$CO<-as.numeric(tabla$CO)

write_csv(tabla,"./tabla_imbalanced.csv")
```

## Hipótesis Iniciales

Existe una correlación relevante del estado del aire con las condiciones climáticas.

Existe una relación entre temperaturas máximas y mediciones de O3.

Hay patrones estacionales en las condiciones del aire, los cuales han evolucionado en los años.

Las leyes y restricciones en la calidad del aire en Santiago tienen influencia real en las condiciones del aire.

Se puede predecir de mejor manera el estado de alerta ambiental utilizando métodos de clasificación, en vez del actual modelo matemático.

De haber una relación entre las condiciones climáticas y la radiación solar receptada por paneles solares, se puede predecir la generación de energía de un campo de paneles solares según el pronóstico.

## Datos

Los datos utilizados durante el proyecto están almacenados y disponibles de manera pública por el Centro de investigación para el clima y la resiliencia (CR2) en el caso de los datos atmosféricos y de temperatura, y en datos.gob.cl para el caso del los datos de contaminación atmosférica pertenecientes al SINCA (MMA) , mientras que la etiqueta del modelo se obtiene mediante 'scrapping' del reporte diario de la situación de alerta ambiental en la página del Ministerio de medio ambiente (http://airesantiago.gob.cl/balance-1997-2017/calidad-del-aire/).

Esto último se logro con los 2 siguientes bloques de código en python. Primero un descargador que realiza la descarga automatica de todos los pdf con la informacion de calidad del aire. Uno por cada dia que se registro esta desde el 2015 (approx. 700)
```{python}
import ssl
from urllib.error import HTTPError
import requests
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains

ssl._create_default_https_context = ssl._create_unverified_context

for i in range(5, 10): # Para cada año que contiene registro
    driver = webdriver.Chrome('/Users/juanpablosuazo/yo/pega/whitestack/tutorials-master/libraries/chromedriver') # se crea el driver que recorrerá la página

    driver.get("http://airesantiago.gob.cl/consolidados-de-calidad-del-aire-ano-201" + str(i) + "/") # se ingresa al directorio que contiene los links a cada pdf
    actions = ActionChains(driver)

    reportes = driver.find_elements_by_partial_link_text('Pron') #se encuentran todos loselementos con links a pdf (todos comienzan con Pron)
    urls = []

    for rep in reportes:
        urls.append(rep.get_attribute('href')) #se extraen los link de descarga

    driver.close() # se cierra el driver

    for url in urls: # por cada link de descarga
        try:
            urlName = str(url).split('/')
            urlN = urlName[len(urlName) - 1] #del lmk de descarga se extrae el nombre del archivo

            r = requests.get(url) # se consigue el pdf

            with open('/Users/juanpablosuazo/UChile/semestre10/mineriaDeDatos/hitos/hito2/reportes/201' + str(
                    i) + '/' + urlN, "wb") as code:
                code.write(r.content) # se descarga el pdf

        except HTTPError:
            print(url) # si se produce error con algún link, se atrapa y se imprime el link problemático

```
Luego, con un parser, se extrae la info relevante de los pdf (día y calidad del aire asociado) y se escriben en un arhivo csv
```{python}
import os
import csv
import slate3k as slate
import sys

with open('/Users/juanpablosuazo/UChile/semestre10/mineriaDeDatos/hitos/hito2/reportes-cvs/pred.csv', 'w') as csvfile:
    filewriter = csv.writer(csvfile, delimiter=',') # se abre el csv a escribir

    for i in range(5, 10): #para cada directorio (1 por año)
        for filename in os.listdir('/Users/juanpablosuazo/UChile/semestre10/mineriaDeDatos/hitos/hito2/reportes/201' + str(i)): # se listan los archivos en el directorio
            if filename.endswith(".pdf"): # si son pdf
                try:
                    with open('/Users/juanpablosuazo/UChile/semestre10/mineriaDeDatos/hitos/hito2/reportes/201' + str(i) + '/' + filename, 'rb') as f: # se abre el pdf para leer
                        extracted_text = slate.PDF(f) # se extrae el texto del pdf
                    
                    # se aprovecha formato similar de los pdf para usar palabras clave y diversas 
                    # herramientas de manejo de strings para obtener la calidad del aire para tal día
                    prediccion = str(extracted_text).replace("\\n", ' ').split('CALIDAD DEL AIRE PREVISTA PARA MAÑANA')
                    pred = prediccion[1].split('*')[0].split('CONDICIÓN')[0] # acá encontramos la predicción acera de la calidad del aire
                    fecha = filename.split('.')[0].replace('Pronostico', '') # del nombre del archivo se extrae la fecha

                    if fecha[0] == 'D':
                        fecha = fecha[22:]
                    if pred[4] == ' ':
                        pr = pred[5:].replace('  ', ' ').replace('  ', ' ').replace('  ', ' ')
                        filewriter.writerow([fecha, pr]) # se escribe la info en el csv
                    else:
                        pr = pred[4:].replace('  ', ' ').replace('  ', ' ').replace('  ', ' ')
                        filewriter.writerow([fecha, pr])
                except:
                    print(filename + ' ' + str(sys.exc_info()[0])) # si hay errores al abrir un pdf, se atrapa y se indica cual fue el pdf que fallo (ya sea por ftener distinto formato, estar corrupto, etc.)
```

De todas maneras se hace necesario usar excel para realizar una pequeña limpieza de los datos y así tener un formato consistente con el ya usado.

### Catacterización de los datos
Los datos están compuestos por fecha, valor de las distintas mediciones y la categorización del estado del aire; la fecha se encuentre en el formato AAAA-MM-DD como también en columnas separadas; las distintas medidas se encuentran en valores numéricos y la categorización se encuentra en formato de texto.

````{r}
head(tabla, n= 3L)
```

#### Correlacion de los datos
```{r}
tabla.cor <- cor(subset(tabla, select = -c(cat_mp10,cat_mp25,Fecha,anno,dia,MP25,NO2)), use = "pairwise.complete.obs" )
corrplot.mixed( tabla.cor )
```
Se encuentran correlaciones entre O3 y MP10 y la temperatura máxima del día; además de una correlación entre MP10, CO y SO2; una correlación esperada es la negativa existente entre precipitaciones y MP10; precipitaciones y Tmax.

A continuación se muestra la curva ROC para un modelo de regrasión multinomial sobre dos subset de relación 70-30.
```{r}

tabla_ss= subset(tabla, select = -c(MP10,MP25))
# tabla_ss$cat_mp10[tabla_ss$cat_mp10=="PREEMERGENCIA"]<-"PRE EMERGENCIA"

tabla_ss$cat_mp10<- as.factor(tabla_ss$cat_mp10)
train_ind=sample(seq_len(nrow(tabla)),size = nrow(tabla)*0.7)
tabla_learn = tabla_ss[train_ind,]
tabla_test = tabla_ss[-train_ind,]

tabla_learn$cat_mp10=relevel(tabla_learn$cat_mp10, ref = "REGULAR")
mod_multi_log=multinom(cat_mp10~O3+CO+Tmedia+Tmax+Precipitaciones, data = tabla_learn)

tabla_test$pred_multilog = predict(mod_multi_log, newdata = tabla_test)

tabla_test<-tabla_test[which(!is.na(tabla_test$pred_multilog)),]

rocs = roc.curve(tabla_test$cat_mp10,tabla_test$pred_multilog, curve = TRUE)
plot(rocs)

summary(mod_multi_log)
```

#### Datos Nulos o Faltantes
Los datos para algunas de las fechas no poseen todas las mediciones, por lo que se deben manejar los casos en que no hay valores en alguna columna. Los valores faltantes por cada columna son:

```{r}
na_count <-sapply(tabla, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
```


```{r inputar datos faltantes}
try(tabla<-subset(tabla, select = -c(SO2,MP25,NO2)))
tabla[which(is.na(tabla$CO)),"CO"]<-median(tabla$CO)
tabla[which(is.na(tabla$MP10)),"MP10"]<-median(tabla$MP10)

lin_fit <-lm(O3~mes+dia+MP10+CO+Tmedia+Tmax+Precipitaciones,data = tabla ,na.action = "na.exclude")
tabla[which(is.na(tabla$O3)),"O3"]<-predict(lin_fit,tabla[which(is.na(tabla$O3)),c("mes","dia","MP10","CO","Tmedia","Tmax","Precipitaciones")])

na_verify = sapply(tabla, function(y) sum(length(which(is.na(y)))))
na_verify <- data.frame(na_verify)
na_verify
```

### Balanceo de las clases

El dataset de caracterización de situación de emergencia en su estado original tiene las clases de 'pre emergencia' y 'pre alerta' subrepresentadas, lo que probablemente explica el mal rendimiento de predicción del modelo Logit multinomial par esas clases. Como solución a este problema se aplicó oversampeling utilizando 'SMOTE' ya que es un problema de oversampeling multiclase. El código para realizar el oversampeling se hizo en python debido a que la implementación de SMOTE en R está pensaba para un clasificador binario, por lo que se utilizó el subpaquete: 'random_oversampeling' de la libreria 'imblearn'.
```{r}
ggplot(emergencia)+geom_bar(aes(`ESTADO MP10`))
```

## Feedback del Hito 1
En general las criticas de los compañeros dirijidas a la presentación son de la presentación misma; estos comentarios fueron tomados completamente, entre los que se encuentran tener un título más descriptivo del proyecto, agregar números a la diapositiva y tener objetivos más claramente definidos; esto último es una critica de la que somos bastante concientes ya que en la realidad no teníamos claro el objetivo final, sino que trabajamos con preguntas abiertas.

Además entre los comentarios hechos a los datos se nos sugiere _ignorar medidas nulas y errores de medición_, critica que tomamos completamente con la salvedad de que el como los ignoramos o eliminamos puede afectar nuestros resultados, ya que en general los datos faltan por periodos de tiempo bien definidos y el simplemente eliminar la columna o medidas muy extremas podrían hacernos perder información que puede ser relevante.
