{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "lab2.2_CC5206_2019-2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "OqjX9ps65puw",
        "colab_type": "text"
      },
      "source": [
        "# Laboratorio 2.2: Clasificación\n",
        "\n",
        "Bárbara Poblete, Felipe Bravo, Aymé Arango, Juglar Díaz, Hernán Sarmiento, Juan Pablo Silva\n",
        "**Septiembre 2019**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "ZCWyfAsx5puy",
        "colab_type": "text"
      },
      "source": [
        "## =================== INTEGRANTES =====================\n",
        "\n",
        "Escriba a continuación el nombre de los integrantes del presente laboratorio:\n",
        "\n",
        "1. \n",
        "\n",
        "2. \n",
        "\n",
        "## ====================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "8NgzWFYI5pu0",
        "colab_type": "text"
      },
      "source": [
        "# Instrucciones\n",
        "\n",
        "\n",
        "1. El formato de entrega es un documento en **.html**, generado por jupyter.\n",
        "\n",
        "2. El laboratorio debe realizarse en grupos de **2 personas**.\n",
        "\n",
        "3. Asegúrese que están los nombres de los integrantes. Sólo uno de los integrantes debe subir este archivo a U-Cursos antes de finalizar la sesión. \n",
        "\n",
        "4. Las respuestas a cada pregunta se deben escribir en los bloques que dicen **RESPUESTA A PREGUNTA X.X**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "dZHEQ8EZ5pvd",
        "colab_type": "text"
      },
      "source": [
        "# Del Laboratorio \n",
        "\n",
        "En este laboratorio vamos a comparar clasificadores con cierto *baselines* o clasificadores base, y además vamos a trabajar con clases desbalanceadas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "59rQLXsm5pve",
        "colab_type": "text"
      },
      "source": [
        "# Parte 1: Comparar clasificadores\n",
        "\n",
        "Una de las principales tareas en enfoques supervisados es evaluar diferentes clasificadores y encontrar el mejor de alguno de ellos para un problema. Por ejemplo, si tenemos dos (o más) clasificadores y queremos compararlos entre sí, nos interesa responder: *¿Cuál de los clasificadores es el mejor?* \n",
        "Para responder esta pregunta, no existe una única solución. \n",
        "\n",
        "Lo que haremos a continuación será ejecutar diferentes clasificadores y compararlos en base a las métricas de Precision, Recall y F1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "59MmjqpV5pvf",
        "colab_type": "text"
      },
      "source": [
        "## Pregunta 1.1  \n",
        "\n",
        "Para realizar la evaluación de distintos clasificadores, vamos a crear la función `run_classifier()`, la cual evalúa un clasificador `clf` recibido como parámetro un dataset `X,y` (dividido en training y testing) y un número de tests llamado `num_test`. Esta función almacena y retorna los valores de precision, recall y f1-score en la variable `metrics` además de los resultados de predicción.\n",
        "\n",
        "\n",
        "En base a lo anterior, incluya las sentencias que ajusten el modelo junto a su correspondiente predicción sobre los datos. No use cross-validation ni tampoco el parámetro `random_state`.\n",
        "\n",
        "\n",
        "### Respuesta 1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "VaAWs6RX5pvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### COMPLETAR ESTE CÓDIGO\n",
        "\n",
        "## run_classifier recibe un clasificador y un dataset dividido para entrenamiento y testing\n",
        "## y opcionalmente la cantidad de resultados que se quiere obtener del clasificador\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "\n",
        "\n",
        "def run_classifier(clf, X, y, num_tests=100):\n",
        "    metrics = {'f1-score': [], 'precision': [], 'recall': []}\n",
        "    \n",
        "\n",
        "    \n",
        "    for _ in range(num_tests):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
        "        ### INICIO COMPLETAR ACÁ \n",
        "        \n",
        "        #### TIP: en base a los set de entrenamiento, genere la variable predictions \n",
        "        #### que contiene las predicciones del modelo\n",
        "        \n",
        "       \n",
        "        \n",
        "        ### FIN COMPLETAR ACÁ\n",
        "        \n",
        "        metrics['y_pred'] = predictions\n",
        "        metrics['y_prob'] = clf.predict_proba(X_test)[:,1]\n",
        "        metrics['f1-score'].append(f1_score(y_test, predictions)) \n",
        "        metrics['recall'].append(recall_score(y_test, predictions))\n",
        "        metrics['precision'].append(precision_score(y_test, predictions))\n",
        "    \n",
        "    return metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "Lwlyx87E5pvz",
        "colab_type": "text"
      },
      "source": [
        "Luego de completar el código anterior, ejecute el siguiente bloque para comparar los distintos clasificadores. \n",
        "Usaremos un **dataset de cáncer de mamas** para evaluar. Información del dataset la puede encontrar en el siguiente link: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "4j4wBg0p5pv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ejecutar este código\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.svm import SVC  # support vector machine classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "bc = load_breast_cancer()    # dataset cancer de mamas\n",
        "X = bc.data\n",
        "y = bc.target\n",
        "\n",
        "c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n",
        "c1 = (\"Decision Tree\", DecisionTreeClassifier())\n",
        "c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n",
        "c3 = (\"KNN\", KNeighborsClassifier(n_neighbors=5))\n",
        "\n",
        "classifiers = [c0,c1, c2, c3]\n",
        "\n",
        "results = {}\n",
        "for name, clf in classifiers:\n",
        "    metrics = run_classifier(clf, X, y)   # hay que implementarla en el bloque anterior.\n",
        "    results[name] = metrics\n",
        "    print(\"----------------\")\n",
        "    print(\"Resultados para clasificador: \",name) \n",
        "    print(\"Precision promedio:\",np.array(metrics['precision']).mean())\n",
        "    print(\"Recall promedio:\",np.array(metrics['recall']).mean())\n",
        "    print(\"F1-score promedio:\",np.array(metrics['f1-score']).mean())\n",
        "    print(\"----------------\\n\\n\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "uk64gSNX5pv9",
        "colab_type": "text"
      },
      "source": [
        "### Pregunta 1.2\n",
        "\n",
        "Analizando los resultados obtenidos de cada clasificador, y basándose en las métricas calculadas. ¿Cuál es el mejor clasificador? ¿Qué métricas observó para tomar esa decisión y por qué? Fundamente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "EcfYD9vW5pv-",
        "colab_type": "text"
      },
      "source": [
        "### Respuesta 1.2\n",
        ":: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhQqOrGs8deT",
        "colab_type": "text"
      },
      "source": [
        "#Parte 2: Seleccionando hiperparámetros\n",
        "Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases. Por ejemplo que kernel usar para Support Vector Classifier, o que criterion para Decision Tree, etc. Es posible y recomendable buscar en el espacio de hiperparámetros la mejor alternativa. Cualquier parámetro proporcionado al construir un estimador puede optimizarse de esta manera. Para encontrar los nombres y los valores actuales de todos los parámetros para un estimador dado puede usar *estimator.get_params()*.\n",
        "\n",
        "Una búsqueda consiste en:\n",
        "\n",
        "*   un estimador (regresor o clasificador como sklearn.svm.SVC ());\n",
        "*   un espacio de parámetros;\n",
        "*   un método para buscar o muestrear candidatos;\n",
        "*   un esquema de validación cruzada; y\n",
        "*   una función de puntuación(score).\n",
        "\n",
        "\n",
        "Tenga en cuenta que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejar sus valores predeterminados. Se recomienda leer la documentación de la clase de estimador para obtener una mejor comprensión de su comportamiento esperado, posiblemente leyendo la referencia adjunta a la literatura."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftr35YoPkhEo",
        "colab_type": "text"
      },
      "source": [
        "###Pregunta 2.1 \n",
        "\n",
        "Una alternativa para seleccionar hiperparámetros es GridSearchCV. GridSearchCV considera exhaustivamente todas las combinaciones de parámetros. GridSearchCV recibe un *estimador*, recibe *param_grid* (un diccionario o una lista de diccionarios con los nombres de los parametros a probar como keys y una lista de los valores a probar), *scoring* una o varias funciones de puntuación (score) para evaluar cada combinación de parametros y *cv* una extrategia para hacer validación cruzada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvtFRHnAvmYy",
        "colab_type": "text"
      },
      "source": [
        "El siguiente código muestra como seleccionar el número de vecinos y que pesos otorgar a los vecinos en un clasificador KNN. \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jme31lpTroM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tuned_parameters = {'n_neighbors': [1,3,5], 'weights': ['uniform','distance']}\n",
        "score = 'precision'\n",
        "\n",
        "clf = GridSearchCV(KNeighborsClassifier(), param_grid=tuned_parameters, cv=5,\n",
        "                       scoring=score)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejor combinación de parámetros:\")\n",
        "print(clf.best_params_)\n",
        " \n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhZ-4ojustZJ",
        "colab_type": "text"
      },
      "source": [
        "###Pregunta\n",
        "*  a) Realice este mismo proceso para un clasificador DecisionTree y los parametros criterion=['gini','entropy'] y max_depth=[1,3,5].\n",
        "*  b) ¿Qué puede decir de los resultados, considera que es necesario seguir explorando los parámetros, fue útil hacer este análisis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo1gdJeOrErl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## RESPUESTA A PREGUNTA 2.1 a)\n",
        "\n",
        "#Completar codigo aca\n",
        "tuned_parameters = {} #Completar tuned_parameters\n",
        "\n",
        "#Repetir el codigo de la seccion anterior con KNN pero ahora con decision tree\n",
        "score = 'precision'\n",
        "\n",
        "#Construir aca el clf con GridSearch y luego entrenar\n",
        "\n",
        "\n",
        "print(\"Mejor combinación de parámetros:\")\n",
        "print(clf.best_params_)\n",
        " \n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF4uhT12yHLQ",
        "colab_type": "text"
      },
      "source": [
        "### Respuesta 2.1 b)\n",
        ":: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "UTMHPOwi5pwD",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Parte 3: Tratando con clases desbalanceadas\n",
        "\n",
        "Para mejorar el rendimiento de un clasificador sobre clases desbalanceadas existen varias técnicas. En esta parte, veremos cómo tratar con este problema usando (sub/over)sampling de las clases.\n",
        "\n",
        "Descargue el dataset `unbalanced.csv` que está en el tutorial. \n",
        "\n",
        "(*Nota: Para ejecutar el siguiente bloque es necesaria la librería `pandas` que viene incluida en Anaconda.*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "Rv_hCdDH5pwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargamos dataset desbalanceado\n",
        "unbalanced = 'unbalanced.csv'\n",
        "unbalanced = https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/unbalanced.csv\n",
        "\n",
        "data = pd.read_csv(unbalanced)  # abrimos el archivo csv y lo cargamos en data.\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "eObPlmBl5pwG",
        "colab_type": "text"
      },
      "source": [
        "Note el desbalance de las clases ejecutando el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "Qum5C0qf5pwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Distribucion de clases original\")\n",
        "data['Class'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee168t5vWIqG",
        "colab_type": "text"
      },
      "source": [
        "Antes de hacer algo para tratar el desbalance entre las clases debemos antes dividir en train-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L88_th9fWaT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, data_test, ytrain, ytest = train_test_split(data, data['Class'], test_size=0.2, stratify=data['Class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaZWIUSvZ3ti",
        "colab_type": "text"
      },
      "source": [
        "Así queda la proporción de clases en el train después de dividir en train-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00j7PK-uZxJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "tch2wO604a9N",
        "colab_type": "text"
      },
      "source": [
        "Ahora, usando el dataset anterior, aplicaremos **oversampling** y **subsampling** al train para que queden balanceados. Ejecute el siguiente código y note ahora que las clases están balanceadas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6IViZylYvXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Distribución de clases usando (over/sub)sampling\")\n",
        "print()\n",
        "\n",
        "data_train = data_train.reset_index(drop=True)\n",
        "\n",
        "# oversampling sobre la clase 1\n",
        "idx = np.random.choice(data_train[data_train['Class'] == 1].index, size=78)\n",
        "data_oversampled = pd.concat([data_train, data_train.iloc[idx]])\n",
        "print(\"Data oversampled on class '1'\")\n",
        "print(data_oversampled['Class'].value_counts())\n",
        "print()\n",
        "\n",
        "\n",
        "# subsampling sobre la clase 0\n",
        "idx = np.random.choice(data_train.loc[data_train.Class == 0].index, size=78, replace=False)\n",
        "data_subsampled = data_train.drop(data_train.iloc[idx].index)\n",
        "print(\"Data subsampled on class '0'\")\n",
        "print(data_subsampled['Class'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "ty6J1yiN5pwR",
        "colab_type": "text"
      },
      "source": [
        "Para la siguiente pregunta, vamos a entrenar un árbol de decisión (`DecisionTreeClassifier`) sobre los 3 datasets por separado (**original**, con **oversampling** y con **subsampling**) y luego comparamos los resultados usando alguna métrica de evaluación.\n",
        "\n",
        "Ejecute el siguiente bloque para cargar los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "l7C896GQ5pwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ejecutar este código para preparar los datos\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Preparando los data frames para ser compatibles con sklearn\n",
        "\n",
        "# datos test\n",
        "X_test = data_test[data_train.columns[:-1]] # todo hasta la penultima columna\n",
        "y_test = data_test[data_train.columns[-1]]  # la última columna\n",
        "\n",
        "\n",
        "# datos entrenamiento \"originales\"\n",
        "X_orig = data_train[data_train.columns[:-1]] \n",
        "y_orig = data_train[data_train.columns[-1]] \n",
        "\n",
        "# datos entrenamiento \"oversampleados\" \n",
        "X_over = data_oversampled[data_train.columns[:-1]]\n",
        "y_over = data_oversampled[data_train.columns[-1]]\n",
        "\n",
        "# datos entrenamiento \"subsampleados\"\n",
        "X_subs = data_subsampled[data_train.columns[:-1]]\n",
        "y_subs = data_subsampled[data_train.columns[-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "-BVDehRR5pwV",
        "colab_type": "text"
      },
      "source": [
        "## Pregunta 3.1\n",
        "\n",
        "Complete el código necesario para ejecutar el clasificador en cada uno de los tres casos. Emplee como datos de entrada lo del bloque anterior. Para cada caso entrene con el dataset correspondiente y evalue con el conjunto de test (será el mismo para los tres casos) obtenido con train_test_split sobre los datos originales. \n",
        "\n",
        "Muestre Precision, Recall y F1-score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "QBTFjbdc5pwW",
        "colab_type": "text"
      },
      "source": [
        "### RESPUESTA PREGUNTA 3.1 (agregue código en el siguiente bloque)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "ynh3E-OG5pwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## RESPUESTA A PREGUNTA 3.1\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Recuerde:\n",
        "##  - instanciar el clasificador con DecisionTreeClassifier()\n",
        "##  - entrenar con fit()\n",
        "##  - hacer las predicciones\n",
        "##  - Mostrar precision, recall y f1-score.\n",
        "\n",
        "\n",
        "# Aca esta el codigo usando el dataset: original \n",
        "print(\"ORIGINAL::::::::::\")\n",
        "clf_orig = DecisionTreeClassifier()\n",
        "\n",
        "clf_orig.fit(X_orig,y_orig)\n",
        "pred_orig = clf_orig.predict(X_test)\n",
        "print(classification_report(y_test, pred_orig))\n",
        "\n",
        "# Complete el resto para oversampling y subsampling \n",
        "\n",
        "\n",
        "print(\"OVERSAMPLING::::::::::\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"SUBSAMPLING::::::::::\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "JQ3zmwB75pwZ",
        "colab_type": "text"
      },
      "source": [
        "## Pregunta 3.2\n",
        "\n",
        "¿Cuál estrategia de sampling entrega mejores resultados para la clase minoritaria? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "gmpKAwxJ5pwa",
        "colab_type": "text"
      },
      "source": [
        "### RESPUESTA A PREGUNTA 3.2\n",
        "::\n",
        "::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "1fdbzorQ5pwb",
        "colab_type": "text"
      },
      "source": [
        "## Pregunta 3.3\n",
        "\n",
        "Indique una desventaja de usar oversampling y una desventaja de usar subsampling en clasificación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "Y89YN06W5pwc",
        "colab_type": "text"
      },
      "source": [
        "### RESPUESTA A PREGUNTA 3.3\n",
        "::\n",
        "::\n",
        "\n"
      ]
    }
  ]
}