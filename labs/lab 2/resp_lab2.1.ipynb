{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Laboratorio 2.1: Clasificación\n",
    "\n",
    " Bárbara Poblete, Felipe Bravo, Aymé Arango, Juglar Díaz, Hernán Sarmiento, Juan Pablo Silva\n",
    "\n",
    " **Septiembre 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## =================== INTEGRANTES =====================\n",
    "\n",
    " Escriba a continuación el nombre de los integrantes del presente laboratorio:\n",
    "\n",
    " 1. Bastián Inostroza\n",
    "\n",
    " 2. Sebastián Guerraty\n",
    "\n",
    " ## ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Instrucciones\n",
    "\n",
    "\n",
    " 1. El formato de entrega es un documento en **.ipynb**, generado por jupyter.\n",
    "\n",
    " 2. Asegúrese que están los nombres de los integrantes. Sólo uno de los integrantes debe subir este archivo a U-Cursos antes de finalizar la sesión.\n",
    "\n",
    " 3. Las respuestas a cada pregunta se deben escribir en los bloques que dicen **RESPUESTA A PREGUNTA X.X**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Del Laboratorio\n",
    "\n",
    " En este laboratorio, primero vamos a hacer un análisis de datos y luego vamos a entrenar un clasificador de 3 maneras:\n",
    "\n",
    " * Entrenar/testear con los mismos datos,\n",
    "\n",
    " * Dividiendo el dataset en una parte para entrenar y otra para testear, y finalmente,\n",
    "\n",
    " * Usando cross-validation. Veremos accuracy, precision y recall para luego analizar los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Parte 1: Evaluar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Usaremos el **Wine Dataset**, que viene en **scikit-learn**. Para ello, ejecutaremos la siguiente línea de código para cargar nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## PREGUNTA 1.1\n",
    "\n",
    " Indique lo siguiente:\n",
    " * Tamaño del dataset.\n",
    " * ¿Cuántas clases son?\n",
    " * ¿Qué nombre tienen las clases?\n",
    " * ¿Cuántas instancias hay de cada clase?\n",
    "\n",
    " Indique en cada caso cómo obtuvo la respuesta, es decir, adjunte código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 1.1\n",
    "## RESPUESTA A PREGUNTA 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 1.2\n",
    "\n",
    " Explique qué hacen las siguientes líneas de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1250x1250 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #carga pyplot desde matplotlib\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True) #carga seaborn\n",
    "import pandas as pd #carga pandas\n",
    "\n",
    "wine = load_wine() #carga los datos default de wine\n",
    "\n",
    "features = pd.DataFrame(data=wine['data'],columns=wine['feature_names']) #crea el dataframe de los features en base a los datos de wine\n",
    "data = features #asigna el df creado a la variable data\n",
    "data['target']=wine['target'] # asgina la variable target dentro de data como los valores de la variable target dentro del df wine\n",
    "data['class']=data['target'].map(lambda ind: wine['target_names'][ind]) # mapea el indicador de target_names de wine a la cariable class en el df data\n",
    "                               \n",
    "\n",
    "g = sns.pairplot(data.iloc[:, 0:5]) # Parametro kind=\"reg\" agrega una recta, hace el plot de distribucion para las variables 0 a la 5 en el df data\n",
    "plt.show() #muestra los plot creados con seaborn en la linea anterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## RESPUESTA A PREGUNTA 1.2\n",
    " - Las primeras 3 lineas cargan las librerias pyplot de matplotlib, seaborn y pandas respectivamente.\n",
    " - la linea de 'wine' carga el dataframe de 'wine' en la variable 'wine'\n",
    " - 'features' crea un dataframe en base a los 'features' del df 'wine' usando los df de pandas\n",
    " - 'data' crea un duplicado de 'features' en la variable 'data'\n",
    " - crea la columna 'target' dentro de data como la columna target dentro de wine\n",
    " - mapea el indicador de target_names de wine a la cariable class en el df data\n",
    " - crea los plot de distrubución de las variables 1 a la 6 usando seaborn\n",
    " - muestra los plot creados con seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 1.3\n",
    "\n",
    " ¿Cuáles son las observaciones principales que puede obtener de la visualización? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 1.3\n",
    " - la variable alchool pareciese ser distribuida uniformemente salvo datos extremos en ambas colas\n",
    " - la variable de acido malico pareciese ser distribucion gama mientras las variables restantes tienen comportamiento que semeja una distribución normal\n",
    " - La disperción de los datos en las variabes de alcohol y ácido malico es mayor al de las variables de distribución normal\n",
    " - A simple vista no pareciese haber una fuerte correlación entre las variables ploteadas, donde se esperaría que la mayor sea una correlación positiva entre la acidez de la ceniza y la cantidad de ceniza en las variables 'acidity_of_ash' y 'ash' respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PARTE 2: Entrenar/testear con los mismos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Usaremos el clasificador **Decision Tree**, utilizando distintas formas de evaluación y vamos a compararlas mediante diversas métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## PREGUNTA 2.1\n",
    "\n",
    " Usando el siguiente código, complete lo que falta para cargar los datos y entrenar el clasificador. Luego, muestre las métricas de accuracy, precision, recall y f1-score utilizando (X,y) como data y etiquetas respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00        71\n",
      "           2       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00       178\n",
      "   macro avg       1.00      1.00      1.00       178\n",
      "weighted avg       1.00      1.00      1.00       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RESPUESTA PREGUNTA 2.1\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "X = wine.data      ## datos, caracteristicas o features de cada flor. \n",
    "y = wine.target    ## clase para cada instancia anterior.\n",
    "\n",
    "# Fit, predict y metricas\n",
    "\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 2.2\n",
    "\n",
    " De acuerdo a las métricas obtenidas ¿Es buena la predicción? ¿Recomendaria utilizar este clasificador en una aplicacion para clasificar vinos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 2.2\n",
    " La predicción es perfecta puesto que el training set es igual al testing set y por ende permitimos que nuestro clasificador se aprenda todas las respuestas.\n",
    " Por estom mismo no recomendaría usar este clasificador, ya que no sabemos como se comporta para datos que no conoce por el *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Parte 3: Otra variante: Dividiendo el dataset para entrenar y testear\n",
    "\n",
    " Ahora lo que haremos será dividir nuestro dataset en 70% entrenar (***training set***) y 30% para testear (***testing set***). Use la función ***train_test_split()*** y utilice las variables `X_train, X_test, y_train, y_test`.\n",
    "\n",
    " ## Pregunta 3.1\n",
    "\n",
    " Escriba el código necesario para entrenar el modelo e indique el Accuracy, Precision y Recall del clasificador.\n",
    " Entrene usando el ***training set*** y pruebe sobre el ***testing set***, en base a la división 70%-30%, respectivamente ¿En qué se diferencian los resultados con respecto a la pregunta 2.1? Cual es mejor? Cual usaria en una aplicacion para clasificar vinos?\n",
    "\n",
    " **NOTA: para dividir el dataset use el parámetro `stratify=y`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        18\n",
      "           1       0.91      0.95      0.93        21\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.94      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### RESPUESTA A PREGUNTA 3.1\n",
    "# Recuerde usar las variables X_train, X_test, y_train, y_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=42, stratify=y)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)    ## Entrenamos con X_train y clases y_train\n",
    "\n",
    "y_pred = clf.predict(X_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 3.1 Continuación\n",
    " En este caso los resultados no son perfectos, obteniendo una precisión tan baja como .89 en class_0; Pero ciertamente es mejor ya que sabemos que aprendió y no memorizó los resultados.\n",
    "Si tuviese que elegir entre los dos, claramente elegiría este para cualquier aplicación, excepto una que funcione sobre el dataset (osea, hacer trampa con el overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 3.2\n",
    "\n",
    " El siguiente código muestra una funcion que genera una matriz de confusión de los resultados de clasificación de la pregunta 3.1. Ejecute el bloque y luego haga una llamada a la funcion *plot_confusion_matrix* con los resultados de la sección 3.1 para visualizar el gráfico. Interprete qué significa cada uno de los valores distintos de 0 en la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "\n",
    "class_names = wine.target_names\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred) \n",
    "    \n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "   \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x279e43f2048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test,y_pred,wine.target_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Los valores de la diagonal es la cantidad de casos correctamente identificados en el grupo de test para cada clase, mientras que el 1 en la primera fila y la segunda columna corresponde a una fila identifiacada como de la clase 'class_1' cuando su valor real es pertenecer a la clase 'class_0'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PARTE 4: Cross-validation\n",
    "\n",
    " Con cross-validation, el conjunto de entrenamiento se divide en $k$ conjuntos disjuntos; se entrena sobre los datos correspondientes a $k-1$ de éstos, y se evalúa sobre el conjunto restante. Esto se repite $k$ veces, evaluando siempre sobre un conjunto distinto. Teniendo en cuenta el parámetro $k$, a éste método se le llama $k$-fold cross-validation.\n",
    "\n",
    " El código que está a continuación realizará 10-fold cross-validation usando Decision Tree sobre los datos. La forma de estimar el rendimiento del clasificador es, entre otras formas, calculando el promedio de todos los k-folds.\n",
    "\n",
    " Además se muestra la predición sobre los datos para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio Precision: 0.9054497354497355\n",
      "Promedio Recall: 0.8936111111111111\n",
      "Promedio F1-score: 0.8898509877921643\n",
      "Promedio Accucary: 0.894702442380461\n"
     ]
    }
   ],
   "source": [
    "## EJECUTAR ESTE BLOQUE\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', 'accuracy', 'f1_macro']\n",
    "cv_results = cross_validate(clf, X, y, cv = 10, scoring = scoring, return_train_score= True)\n",
    "\n",
    "print('Promedio Precision:', np.mean(cv_results['test_precision_macro']))\n",
    "print('Promedio Recall:', np.mean(cv_results['test_recall_macro']))\n",
    "print('Promedio F1-score:', np.mean(cv_results['test_f1_macro']))\n",
    "print('Promedio Accucary:', np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "# Si quisieramos mostrar el resultado de cada k-fold, deberiamos quitar \n",
    "# la funcion np.mean para calcular el promedio. Esto mostraria una lista con el resultado de cada fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 4.1\n",
    "\n",
    " Comente el resultado obtenido y compare los valores de las métricas con respecto a lo obtenido en la pregunta 3.2 ¿Qué beneficios tiene emplear cross-validation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA PREGUNTA 4.1\n",
    " El resultado de la pregunt 3.1 es un mejor clasificador que el obtenido en la pregunta 4.1, ya que todos los indicadores de fitting derivados de la matriz de confusión entregan un valor más cercano a 1 que el testeo con la muestra aleatoria tradicional.\n",
    " La ventaja de utilizar cross validation es que permite entrenar el modelo prácticamente eliminando el sesgo inducido al entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PARTE 5: FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 5.1\n",
    "\n",
    " Respecto a los 3 tipos de experimentos, ¿qué tipo de evaluación considera que es el mejor y por qué? (Refiérase a tamaño del dataset, distribución de clases, entre otras cosas.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 5.1\n",
    " Consideramos que el mejor en nuestros test es el Arbol de decisiones, ya que tanto si se usa o no *cross-validation* obtiene resultados mucho mejores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pregunta 5.2\n",
    "\n",
    " Entrene un clasificador empleando k-nearest neighbors (**KNN**) considerando 5 vecinos y cross validation de 10 folds.\n",
    "\n",
    " Compare el resultado de cross validation obtenido usando Decision Tree y KNN. ¿Hay algún efecto notorio en cuanto al desempeño de ambos clasificadores? ¿Se podría decir que uno es mejor que otro? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para k-nearest neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        18\n",
      "           1       0.78      0.67      0.72        21\n",
      "           2       0.50      0.60      0.55        15\n",
      "\n",
      "    accuracy                           0.72        54\n",
      "   macro avg       0.72      0.72      0.72        54\n",
      "weighted avg       0.74      0.72      0.73        54\n",
      "\n",
      "Promedio Precision: 0.6714502164502163\n",
      "Promedio Recall: 0.6602777777777777\n",
      "Promedio F1-score: 0.6453775853775853\n",
      "Promedio Accucary: 0.6757739938080495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basty\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\basty\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Para cargar KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "K = 5 # numero de vecinos\n",
    "knn = KNeighborsClassifier(n_neighbors=K)  \n",
    "\n",
    "## AGREGUE CODIGO PREGUNTA 5.2\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Para k-nearest neighbors\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', 'accuracy', 'f1_macro']\n",
    "cv_results = cross_validate(knn, X, y, cv = 10, scoring = scoring, return_train_score= True)\n",
    "\n",
    "print('Promedio Precision:', np.mean(cv_results['test_precision_macro']))\n",
    "print('Promedio Recall:', np.mean(cv_results['test_recall_macro']))\n",
    "print('Promedio F1-score:', np.mean(cv_results['test_f1_macro']))\n",
    "print('Promedio Accucary:', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### RESPUESTA A PREGUNTA 5.2 (EXPLICACION)\n",
    "Existe una diferencia en desempeño muy notoria entre el árbol de decisiones y KNN correspondiente a aprox un 20% de desempeño en general. Por esto podríamos aventurar que el árbol de decisiones es mejor que knn.\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
